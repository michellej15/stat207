{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12 Building Parsimonious Models - Individual - [25 points] - Solutions\n",
    "\n",
    "\n",
    "## <u>Case Study</u>: Creating an Classifer Model that will Accurately Predict whether an Instagram Account is Fake or Real *with New Data*\n",
    "\n",
    "We will revisit the fake_insta_cleaned.csv dataset one more time. In this case, we would like to build a **parsimonious** logistic regression model that predicts the probability that an account is fake. To help us find this parsimonious model we will consider all of the other remaining variables as potential explanatory variables to include in the model.\n",
    "\n",
    "* the number of accounts someone *follows*\n",
    "* number of *followers*\n",
    "* number of posts\n",
    "* number of words in name\n",
    "* number of characters in the bio\n",
    "* whether they have a profile picture or not\n",
    "\n",
    "We will use the following two methods to help us find a parsimonious model.\n",
    "1. Backward Elimination Algorithm with AIC score \n",
    "2. Regularized Logistic Regression\n",
    "\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "<table style=\"border: none;border-collapse: collapse;width:102pt;\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;width:51pt;\">Problem</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;border-left:none;width:51pt;\">Points</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">4</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">5.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">7.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">7.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">7.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.6</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.7</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.8</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.9</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile as zp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preliminaries\n",
    "### 1.1  Read the fake_insta_cleaned.csv into a dataframe called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_insta_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>164</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>833</td>\n",
       "      <td>3572</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>1695</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>68</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0                 yes                        1                     30   \n",
       "1                 yes                        5                     64   \n",
       "2                 yes                        2                     82   \n",
       "3                 yes                        1                     76   \n",
       "4                 yes                        1                      0   \n",
       "..                ...                      ...                    ...   \n",
       "107               yes                        1                      0   \n",
       "108               yes                        1                      0   \n",
       "109               yes                        2                      0   \n",
       "110                no                        1                      0   \n",
       "111               yes                        1                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  \n",
       "0                 35                  488                604         real  \n",
       "1                  3                   35                  6         real  \n",
       "2                319                  328                668         real  \n",
       "3                  6                  225                356         real  \n",
       "4                  6                  362                424         real  \n",
       "..               ...                  ...                ...          ...  \n",
       "107               13                  114                811         fake  \n",
       "108                4                  150                164         fake  \n",
       "109                3                  833               3572         fake  \n",
       "110                1                  219               1695         fake  \n",
       "111                3                   39                 68         fake  \n",
       "\n",
       "[112 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.  Next, create a new variable y in df that is equal to 1 when the the account is fake and that is equal to 0 when the account is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>164</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>833</td>\n",
       "      <td>3572</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>1695</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>68</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0                 yes                        1                     30   \n",
       "1                 yes                        5                     64   \n",
       "2                 yes                        2                     82   \n",
       "3                 yes                        1                     76   \n",
       "4                 yes                        1                      0   \n",
       "..                ...                      ...                    ...   \n",
       "107               yes                        1                      0   \n",
       "108               yes                        1                      0   \n",
       "109               yes                        2                      0   \n",
       "110                no                        1                      0   \n",
       "111               yes                        1                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  y  \n",
       "0                 35                  488                604         real  0  \n",
       "1                  3                   35                  6         real  0  \n",
       "2                319                  328                668         real  0  \n",
       "3                  6                  225                356         real  0  \n",
       "4                  6                  362                424         real  0  \n",
       "..               ...                  ...                ...          ... ..  \n",
       "107               13                  114                811         fake  1  \n",
       "108                4                  150                164         fake  1  \n",
       "109                3                  833               3572         fake  1  \n",
       "110                1                  219               1695         fake  1  \n",
       "111                3                   39                 68         fake  1  \n",
       "\n",
       "[112 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = df['account_type'].map({'real':0, 'fake':1})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Test Data\n",
    "\n",
    "First, we want to create a training dataset to train the dataset and a test dataset to test the model's performance.\n",
    "\n",
    "### 2.1. First, create a training dataset and a test dataset where:\n",
    "* the training dataset is comprised of a random sample of 85% of the rows in our dataframe,\n",
    "* the test dataset is comprised of the remaining 15% of rows in the dataframe, and\n",
    "* we use a random state of 456."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.15, random_state = 456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>386</td>\n",
       "      <td>363</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>276</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>463</td>\n",
       "      <td>2267</td>\n",
       "      <td>466</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>573</td>\n",
       "      <td>474</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>118</td>\n",
       "      <td>461</td>\n",
       "      <td>1055</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>238</td>\n",
       "      <td>1381</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>366</td>\n",
       "      <td>552</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "107               yes                        1                      0   \n",
       "47                yes                        1                     13   \n",
       "19                yes                        1                      0   \n",
       "38                yes                        2                     77   \n",
       "52                yes                        2                    146   \n",
       "..                ...                      ...                    ...   \n",
       "42                yes                        2                      0   \n",
       "89                yes                        1                      0   \n",
       "43                yes                        2                     18   \n",
       "101               yes                        1                      0   \n",
       "27                yes                        2                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  y  \n",
       "107               13                  114                811         fake  1  \n",
       "47                14                  386                363         real  0  \n",
       "19                 0                  189                276         real  0  \n",
       "38               463                 2267                466         real  0  \n",
       "52               145                  573                474         real  0  \n",
       "..               ...                  ...                ...          ... ..  \n",
       "42                 0                   87                 40         real  0  \n",
       "89                81                   75                 55         fake  1  \n",
       "43               118                  461               1055         real  0  \n",
       "101               60                  238               1381         fake  1  \n",
       "27                 9                  366                552         real  0  \n",
       "\n",
       "[95 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>185</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>1445</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>449</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>251</td>\n",
       "      <td>223</td>\n",
       "      <td>694</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>341</td>\n",
       "      <td>2287</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>138</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>192</td>\n",
       "      <td>141</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>82</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>235</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>229</td>\n",
       "      <td>492</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>926</td>\n",
       "      <td>4239</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0                 yes                        1                     30   \n",
       "36                yes                        0                     47   \n",
       "75                yes                        1                      0   \n",
       "3                 yes                        1                     76   \n",
       "99                 no                        1                    112   \n",
       "29                yes                        2                      0   \n",
       "18                yes                        2                     39   \n",
       "73                yes                        1                      0   \n",
       "76                 no                        1                      0   \n",
       "24                yes                        1                     27   \n",
       "2                 yes                        2                     82   \n",
       "13                yes                        2                     43   \n",
       "57                 no                        2                      0   \n",
       "103               yes                        1                      0   \n",
       "59                 no                        3                      0   \n",
       "9                 yes                        1                      0   \n",
       "100                no                        1                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  y  \n",
       "0                 35                  488                604         real  0  \n",
       "36                 2                  510                185         real  0  \n",
       "75                 0                   45                 64         fake  1  \n",
       "3                  6                  225                356         real  0  \n",
       "99                 4                  415               1445         fake  1  \n",
       "29                 8                  400                449         real  0  \n",
       "18               251                  223                694         real  0  \n",
       "73                 8                  341               2287         fake  1  \n",
       "76                 0                   21                 31         fake  1  \n",
       "24                28                  116                138         real  0  \n",
       "2                319                  328                668         real  0  \n",
       "13                60                  192                141         real  0  \n",
       "57                 0                   22                 82         fake  1  \n",
       "103                0                   49                235         fake  1  \n",
       "59                 0                    9                 25         fake  1  \n",
       "9                 53                  229                492         real  0  \n",
       "100                0                  926               4239         fake  1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Model\n",
    "\n",
    "Next, we would like for our 'full model' to predict the probability that an account is fake, using ALL of the following available explanatory variables.\n",
    "* the number of accounts someone *follows*\n",
    "* number of *followers*\n",
    "* number of posts\n",
    "* number of words in name\n",
    "* number of characters in the bio\n",
    "* whether they have a profile picture or not\n",
    "\n",
    "### 3.1. Fit the full model with all six of these explanatory variables using just your *training dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.122645\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    88</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 10 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.8227</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:09:09</td>     <th>  Log-Likelihood:    </th> <td> -11.651</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.015e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  106.9158</td> <td>  1.2e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-2.35e+05</td> <td> 2.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_a_profile_pic[T.yes]</th> <td> -101.7707</td> <td>  1.2e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-2.35e+05</td> <td> 2.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>        <td>    0.0098</td> <td>    0.003</td> <td>    3.168</td> <td> 0.002</td> <td>    0.004</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>      <td>   -0.0299</td> <td>    0.010</td> <td>   -3.107</td> <td> 0.002</td> <td>   -0.049</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_posts</th>          <td>    0.0084</td> <td>    0.009</td> <td>    0.973</td> <td> 0.331</td> <td>   -0.009</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th>  <td>   -1.4222</td> <td>    0.621</td> <td>   -2.290</td> <td> 0.022</td> <td>   -2.640</td> <td>   -0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>    <td>   -0.1171</td> <td>    0.053</td> <td>   -2.201</td> <td> 0.028</td> <td>   -0.221</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.52 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       88\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.8227\n",
       "Time:                        15:09:09   Log-Likelihood:                -11.651\n",
       "converged:                      False   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.015e-21\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  106.9158    1.2e+05      0.001      0.999   -2.35e+05    2.35e+05\n",
       "has_a_profile_pic[T.yes]  -101.7707    1.2e+05     -0.001      0.999   -2.35e+05    2.35e+05\n",
       "number_of_follows            0.0098      0.003      3.168      0.002       0.004       0.016\n",
       "number_of_followers         -0.0299      0.010     -3.107      0.002      -0.049      -0.011\n",
       "number_of_posts              0.0084      0.009      0.973      0.331      -0.009       0.025\n",
       "number_of_words_in_name     -1.4222      0.621     -2.290      0.022      -2.640      -0.205\n",
       "num_characters_in_bio       -0.1171      0.053     -2.201      0.028      -0.221      -0.013\n",
       "============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.52 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_full = smf.logit('y ~ number_of_follows + number_of_followers + number_of_posts + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "mod_full.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.    Backwards Elimination\n",
    "\n",
    "Next, starting with the full model, use a backwards elimination algorithm that seeks to find the model with the lowest **AIC** score. You should fit each of these models in the algorithm with *just the training dataset*. Once the algorithm has stopped, print out the summary output of your **final model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.122645\n",
      "         Iterations: 35\n",
      "Iteration 1: AIC of current model 37.30246959104128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "current_mod = smf.logit('y ~ number_of_follows + number_of_followers + number_of_posts + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('Iteration 1: AIC of current model', current_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.331365\n",
      "         Iterations: 35\n",
      "AIC of current model that deletes number_of_follows 74.95943769115172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#deleting number_of_follows\n",
    "test_mod = smf.logit('y ~ number_of_followers + number_of_posts + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('AIC of current model that deletes number_of_follows', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.276135\n",
      "         Iterations: 35\n",
      "AIC of current model that deletes number_of_followers 64.46572563330452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#deletes number_of_followers\n",
    "test_mod = smf.logit('y ~ number_of_follows + number_of_posts + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('AIC of current model that deletes number_of_followers', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.125481\n",
      "         Iterations: 35\n",
      "AIC of current model that deletes number_of_posts 35.84137144664042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#deletes number_of_posts\n",
    "test_mod = smf.logit('y ~ number_of_follows + number_of_followers + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('AIC of current model that deletes number_of_posts', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.125481\n",
      "         Iterations: 35\n",
      "Iteration 2: AIC of the current model 35.84137144664042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "current_mod = smf.logit('y ~ number_of_follows + number_of_followers + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('Iteration 2: AIC of the current model', current_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.344200\n",
      "         Iterations: 35\n",
      "AIC of current model that deletes number_of_follows 75.39806057027376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#deletes number_of_follows\n",
    "test_mod = smf.logit('y ~  number_of_followers + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('AIC of current model that deletes number_of_follows', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.286734\n",
      "         Iterations: 35\n",
      "AIC of current model that deletes number_of_followers 64.47943290808091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#deletes number_of_followers\n",
    "test_mod = smf.logit('y ~  number_of_follows + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('AIC of current model that deletes number_of_followers', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.152157\n",
      "         Iterations: 35\n",
      "AIC of current model that deletes number_of_words_in_name 38.909752825917934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#deletes number_of_words_in_name\n",
    "test_mod = smf.logit('y ~  number_of_follows + number_of_followers + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "print('AIC of current model that deletes number_of_words_in_name', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.223078\n",
      "         Iterations: 35\n",
      "AIC of current model that deletes num_characters_in_bio 52.38490360405293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#deletes num_characters_in_bio\n",
    "test_mod = smf.logit('y ~  number_of_follows + number_of_followers + number_of_words_in_name + has_a_profile_pic', data = df_train).fit()\n",
    "print('AIC of current model that deletes num_characters_in_bio', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343064\n",
      "         Iterations 9\n",
      "AIC of current model that deletes has_a_profile_pic 75.1822506514567\n"
     ]
    }
   ],
   "source": [
    "#deletes has_a_profile_pic\n",
    "test_mod = smf.logit('y ~  number_of_follows + number_of_followers + number_of_words_in_name + num_characters_in_bio', data = df_train).fit()\n",
    "print('AIC of current model that deletes has_a_profile_pic', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.125481\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    89</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 10 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.8186</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:09:10</td>     <th>  Log-Likelihood:    </th> <td> -11.921</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.321e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  103.9262</td> <td> 2.29e+05</td> <td>    0.000</td> <td> 1.000</td> <td> -4.5e+05</td> <td>  4.5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_a_profile_pic[T.yes]</th> <td>  -98.8981</td> <td> 2.29e+05</td> <td>   -0.000</td> <td> 1.000</td> <td> -4.5e+05</td> <td>  4.5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>        <td>    0.0093</td> <td>    0.003</td> <td>    3.211</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>      <td>   -0.0284</td> <td>    0.009</td> <td>   -3.146</td> <td> 0.002</td> <td>   -0.046</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th>  <td>   -1.3617</td> <td>    0.606</td> <td>   -2.246</td> <td> 0.025</td> <td>   -2.550</td> <td>   -0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>    <td>   -0.1060</td> <td>    0.050</td> <td>   -2.141</td> <td> 0.032</td> <td>   -0.203</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.51 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       89\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.8186\n",
       "Time:                        15:09:10   Log-Likelihood:                -11.921\n",
       "converged:                      False   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.321e-21\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  103.9262   2.29e+05      0.000      1.000    -4.5e+05     4.5e+05\n",
       "has_a_profile_pic[T.yes]   -98.8981   2.29e+05     -0.000      1.000    -4.5e+05     4.5e+05\n",
       "number_of_follows            0.0093      0.003      3.211      0.001       0.004       0.015\n",
       "number_of_followers         -0.0284      0.009     -3.146      0.002      -0.046      -0.011\n",
       "number_of_words_in_name     -1.3617      0.606     -2.246      0.025      -2.550      -0.173\n",
       "num_characters_in_bio       -0.1060      0.050     -2.141      0.032      -0.203      -0.009\n",
       "============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.51 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mod = smf.logit('y ~ number_of_follows + number_of_followers + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "final_mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parsimonious Model Evaluation\n",
    "\n",
    "### 5.1.   Compare the BIC score from your final model (from #4) to your full model (from #3). Use the BIC score to assess which of these models is more of a parsimonious model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.164632796243666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mod.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.17960783224507"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_full.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is more of a parsimonious model because it has a lower BIC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. More About Models\n",
    "\n",
    "### 6.1.   Considering the six possible explanatory variables we *could* include in a logistic regression, how many possible logistic regression models could we create with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "6 + 5 + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.   Which of the following logistic regression models would be *less likely* to be overfit the model (using the training data)? Explain.\n",
    "a. A model that predicts fake accounts using: number_of_followers and number_of_follows? \n",
    "\n",
    "b. A model that predicts fake accounts using: num_characters_in_bio and number_of_words_in_name? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592487\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    92</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 10 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.1435</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:09:10</td>     <th>  Log-Likelihood:    </th> <td> -56.286</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>8.020e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>    0.4552</td> <td>    0.291</td> <td>    1.564</td> <td> 0.118</td> <td>   -0.115</td> <td>    1.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th> <td>   -0.0028</td> <td>    0.001</td> <td>   -2.860</td> <td> 0.004</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>   <td>    0.0011</td> <td>    0.000</td> <td>    2.785</td> <td> 0.005</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       92\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.1435\n",
       "Time:                        15:09:10   Log-Likelihood:                -56.286\n",
       "converged:                       True   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 8.020e-05\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept               0.4552      0.291      1.564      0.118      -0.115       1.026\n",
       "number_of_followers    -0.0028      0.001     -2.860      0.004      -0.005      -0.001\n",
       "number_of_follows       0.0011      0.000      2.785      0.005       0.000       0.002\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1 = smf.logit(formula='y ~ number_of_followers + number_of_follows', data=df_train).fit()\n",
    "mod1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.424546\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    92</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 10 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.3863</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:09:36</td>     <th>  Log-Likelihood:    </th> <td> -40.332</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>9.446e-12</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    1.9773</td> <td>    0.574</td> <td>    3.445</td> <td> 0.001</td> <td>    0.852</td> <td>    3.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>   <td>   -0.0858</td> <td>    0.027</td> <td>   -3.127</td> <td> 0.002</td> <td>   -0.140</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th> <td>   -0.6340</td> <td>    0.361</td> <td>   -1.756</td> <td> 0.079</td> <td>   -1.342</td> <td>    0.073</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       92\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.3863\n",
       "Time:                        15:09:36   Log-Likelihood:                -40.332\n",
       "converged:                       True   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 9.446e-12\n",
       "===========================================================================================\n",
       "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   1.9773      0.574      3.445      0.001       0.852       3.102\n",
       "num_characters_in_bio      -0.0858      0.027     -3.127      0.002      -0.140      -0.032\n",
       "number_of_words_in_name    -0.6340      0.361     -1.756      0.079      -1.342       0.073\n",
       "===========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = smf.logit(formula='y ~ num_characters_in_bio + number_of_words_in_name', data=df_train).fit()\n",
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model that predicts fake accounts using: num_characters_in_bio and number_of_words_in_name is less likely to overfit the data because it has a larger log-likelihood value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Testing\n",
    "\n",
    "Finally, we would like to test our \"final model\" (from 4) on the **test dataset**.\n",
    "\n",
    "### 7.1.   Plot the ROC and calculate the AUC for the \"final model\" (from 4) with the *test dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000435\n",
       "36    0.000003\n",
       "75    0.951887\n",
       "3     0.000575\n",
       "99    1.000000\n",
       "29    0.007642\n",
       "18    0.153684\n",
       "73    1.000000\n",
       "76    1.000000\n",
       "24    0.231045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat_test = final_mod.predict(exog=df_test)\n",
    "phat_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "      <th>phat_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>185</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>1445</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>449</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>251</td>\n",
       "      <td>223</td>\n",
       "      <td>694</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>341</td>\n",
       "      <td>2287</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>138</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>192</td>\n",
       "      <td>141</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>82</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>235</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>229</td>\n",
       "      <td>492</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>926</td>\n",
       "      <td>4239</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0                 yes                        1                     30   \n",
       "36                yes                        0                     47   \n",
       "75                yes                        1                      0   \n",
       "3                 yes                        1                     76   \n",
       "99                 no                        1                    112   \n",
       "29                yes                        2                      0   \n",
       "18                yes                        2                     39   \n",
       "73                yes                        1                      0   \n",
       "76                 no                        1                      0   \n",
       "24                yes                        1                     27   \n",
       "2                 yes                        2                     82   \n",
       "13                yes                        2                     43   \n",
       "57                 no                        2                      0   \n",
       "103               yes                        1                      0   \n",
       "59                 no                        3                      0   \n",
       "9                 yes                        1                      0   \n",
       "100                no                        1                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  y  \\\n",
       "0                 35                  488                604         real  0   \n",
       "36                 2                  510                185         real  0   \n",
       "75                 0                   45                 64         fake  1   \n",
       "3                  6                  225                356         real  0   \n",
       "99                 4                  415               1445         fake  1   \n",
       "29                 8                  400                449         real  0   \n",
       "18               251                  223                694         real  0   \n",
       "73                 8                  341               2287         fake  1   \n",
       "76                 0                   21                 31         fake  1   \n",
       "24                28                  116                138         real  0   \n",
       "2                319                  328                668         real  0   \n",
       "13                60                  192                141         real  0   \n",
       "57                 0                   22                 82         fake  1   \n",
       "103                0                   49                235         fake  1   \n",
       "59                 0                    9                 25         fake  1   \n",
       "9                 53                  229                492         real  0   \n",
       "100                0                  926               4239         fake  1   \n",
       "\n",
       "     phat_test  \n",
       "0     0.000435  \n",
       "36    0.000003  \n",
       "75    0.951887  \n",
       "3     0.000575  \n",
       "99    1.000000  \n",
       "29    0.007642  \n",
       "18    0.153684  \n",
       "73    1.000000  \n",
       "76    1.000000  \n",
       "24    0.231045  \n",
       "2     0.000076  \n",
       "13    0.001681  \n",
       "57    1.000000  \n",
       "103   0.988565  \n",
       "59    1.000000  \n",
       "9     0.851060  \n",
       "100   1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['phat_test']=phat_test\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_pew, tpr_pew, score_pew = roc_curve(y_true=df_test['y'], y_score=df_test['phat_test'])\n",
    "auc_pew = roc_auc_score(y_true=df_test['y'], y_score=df_test['phat_test'])\n",
    "auc_pew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_roc(fpr, tpr, auc, lw=2):\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw,\n",
    "             label='ROC curve (area = '+str(round(auc,3))+')')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "plot_roc(fpr_pew, tpr_pew, auc_pew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC for the final model is 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.    How effective will this model be at classifying Instagram accounts in the *test dataset*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the AUC is 1.0, this tells us that there does exist some predictive probability threshold that is very close to giving us the ideal scenario of a model with a false positive rate of 0 and a true positive rate of 1 with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.   Finally, find a predictive probability threshold that will give you the \"best\" false positive rate and true positive rate for the *test dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  tpr  fpr\n",
       "0        0.9  1.0  0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def tpr_fpr_thres(y, pred_prob, thresh):\n",
    "    yhat = 1 * (pred_prob >= thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y, y_pred=yhat).ravel()\n",
    "    tpr = tp / (fn + tp)\n",
    "    fpr = fp / (fp + tn)\n",
    "    return pd.DataFrame({'threshold':[thresh], 'tpr':[tpr], 'fpr':[fpr]})\n",
    "\n",
    "tpr_fpr_thres(df_test['y'], df_test['phat_test'], 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictive probability threshold = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Regularized Logistic Regression\n",
    "\n",
    "Next, we would also like to use regularized logistic regression as a way to select potential reduced models that may be more parsimonious than the full model.\n",
    "\n",
    "### 8.1. Explanatory Variables Dataframe\n",
    "\n",
    "First, create a dataframe that is comprised of the six possible explanatory variables in your **training dataset**. Any categorical variables (with $w$ levels) in your training dataframe should be represented as $w-1$ 0/1 indicator variables in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['has_a_profile_pic', 'number_of_words_in_name', 'num_characters_in_bio',\n",
       "       'number_of_posts', 'number_of_followers', 'number_of_follows',\n",
       "       'account_type', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>has_a_profile_pic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_words_in_name  num_characters_in_bio  number_of_posts  \\\n",
       "0                        1                     30               35   \n",
       "1                        5                     64                3   \n",
       "2                        2                     82              319   \n",
       "3                        1                     76                6   \n",
       "4                        1                      0                6   \n",
       "\n",
       "   number_of_followers  number_of_follows  has_a_profile_pic_yes  \n",
       "0                  488                604                      1  \n",
       "1                   35                  6                      1  \n",
       "2                  328                668                      1  \n",
       "3                  225                356                      1  \n",
       "4                  362                424                      1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.get_dummies(X, drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "107    1\n",
       "108    1\n",
       "109    1\n",
       "110    1\n",
       "111    1\n",
       "Name: y, Length: 112, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['y']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Response Variable Series\n",
    "\n",
    "Next, create a pandas series that is comprised of your 0/1 response variable in the **training dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "107    1\n",
       "108    1\n",
       "109    1\n",
       "110    1\n",
       "111    1\n",
       "Name: y, Length: 112, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(y)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Non-Regularized Logistic Regression\n",
    "\n",
    "Next, fit a non-regularized logistic regression model using the following specifications:\n",
    "* Use the newton-cg optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "\n",
    "After fitting the model, display the slopes for this non-regularized logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0 = LogisticRegression(penalty='none', solver='newton-cg', \n",
    "                          max_iter=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf0.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4. LASSO Logistic Regression\n",
    "\n",
    "Next, fit a LASSO logistic regression model using the following specifications:\n",
    "* Use the liblinear optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "* Use a value of $\\lambda=10$.\n",
    "\n",
    "After fitting the model, display the slopes for this LASSO logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression('l1', solver='liblinear', \n",
    "                          max_iter=2000, C=1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5. Ridge Logistic Regression\n",
    "\n",
    "Next, fit a ridge logistic regression model using the following specifications:\n",
    "* Use the newton-cg optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "* Use a value of $\\lambda=10$.\n",
    "\n",
    "After fitting the model, display the slopes for this ridge logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression('l2', solver='newton-cg', \n",
    "                          max_iter=2000, C=1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6. Elastic Net Logistic Regression\n",
    "\n",
    "Next, fit an elastic net logistic regression model using the following specifications:\n",
    "* Use the saga optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "* Use a value of $\\lambda=10$.\n",
    "* **We would like to choose from either using $\\alpha=0.25$ or $\\alpha=0.75$ to use in this elastic net model. Use the value of $\\alpha$ which will encourage the values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$ to look like more of what we would get if we were using a logistic ridge regression model.**\n",
    "\n",
    "After fitting the model, display the slopes for this elastic net logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = LogisticRegression('elasticnet', solver='saga', \n",
    "                          max_iter=2000, l1_ratio=0.75, C=1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellejun/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=0.75, max_iter=2000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='elasticnet',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7. Finding Another Prospective Reduced Model\n",
    "\n",
    "Let's use the results of our LASSO model to help us determine one final reduced model to try out. Which explanatory variables are the LASSO model results suggesting should unambiguously **not** be in a parsimonious model? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.04017564, -0.02545354, -0.00099622,  0.0025537 ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number_of_words_in_name and has_a_profile_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8 Fit the New Reduced Model\n",
    "\n",
    "Fit a new reduced model (with the **training dataset**), leaving out the explanatory variables that were suggested to be left out by the LASSO model. Display the summary output table for this new reduced model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.350453\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    90</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 10 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.4934</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:01:29</td>     <th>  Log-Likelihood:    </th> <td> -33.293</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.769e-13</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>    1.2734</td> <td>    0.394</td> <td>    3.229</td> <td> 0.001</td> <td>    0.500</td> <td>    2.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th> <td>   -0.1054</td> <td>    0.040</td> <td>   -2.643</td> <td> 0.008</td> <td>   -0.183</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_posts</th>       <td>   -0.0215</td> <td>    0.013</td> <td>   -1.644</td> <td> 0.100</td> <td>   -0.047</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>     <td>    0.0013</td> <td>    0.001</td> <td>    2.398</td> <td> 0.016</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>   <td>   -0.0010</td> <td>    0.001</td> <td>   -1.427</td> <td> 0.154</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.13 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       90\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Wed, 10 Nov 2021   Pseudo R-squ.:                  0.4934\n",
       "Time:                        16:01:29   Log-Likelihood:                -33.293\n",
       "converged:                       True   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.769e-13\n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                 1.2734      0.394      3.229      0.001       0.500       2.046\n",
       "num_characters_in_bio    -0.1054      0.040     -2.643      0.008      -0.183      -0.027\n",
       "number_of_posts          -0.0215      0.013     -1.644      0.100      -0.047       0.004\n",
       "number_of_follows         0.0013      0.001      2.398      0.016       0.000       0.002\n",
       "number_of_followers      -0.0010      0.001     -1.427      0.154      -0.002       0.000\n",
       "=========================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.13 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_mod = smf.logit(formula='y ~ num_characters_in_bio + number_of_posts + number_of_follows + number_of_followers', data=df_train).fit()\n",
    "reduced_mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.9 Comparing BIC Scores\n",
    "\n",
    "Compare the BIC scores of the full model (ie. the model that uses all 6 possible explanatory variables) and this new reduced model. Which of these two models does the BIC score suggest is more parsimonious? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.17960783224507"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_full.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.35546293961194"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_mod.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full model is more parsimonious because it has a lower BIC value"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
